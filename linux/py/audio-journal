#!/usr/bin/env python3

import argparse
import asyncio
import boto3
import eyed3
import hashlib
import itertools
import json
import logging
import mimetypes
import os
import pathlib
import re
import shutil
import socket
import subprocess
import sys
import tempfile
import urllib

from enum import Enum
from base64 import b64encode
from datetime import date, time, datetime

s3 = boto3.resource("s3")
s3_client = boto3.client("s3")

logger = None
def setup_logger(level):
    l = logging.getLogger("audio-journal")
    l.setLevel(level)

    ch = logging.StreamHandler()
    ch.setLevel(level)

    f = logging.Formatter(
        fmt="%(asctime)s:%(name)s:%(levelname)s %(message)s",
        datefmt="%Y-%m-%dT%H:%M:%S%z")
    ch.setFormatter(f)

    l.addHandler(ch)

    return l

def parse_args():
    parser = argparse.ArgumentParser(
            description="Audio Journal command line interface",
            formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    subparsers = parser.add_subparsers(help="sub-commands", dest='command', required=True)

    home = pathlib.Path.home()
    default_cache = home / ".cache" / "audio-journal"

    parser.add_argument("--log", default="INFO", help="set log level")
    parser.add_argument("--bucket", default="rootmos-sounds", help="S3 bucket")
    parser.add_argument("--cache", default=default_cache, help="cache")

    list_cmd = subparsers.add_parser("list", help="list sounds")
    list_cmd.add_argument("prefix", metavar="PREFIX", nargs="*")

    record = subparsers.add_parser("record", help="record track")
    record.add_argument("--loop", action="store_true", help="continuously record and process sounds")

    gui = subparsers.add_parser("gui", help="run the GUI")

    return parser.parse_args()

class Cache:
    def __init__(self, path):
        self.path = path

    def _lazy_init(self):
        if not self.path.exists():
            logger.info(f"creating cache: {self.path}")
            self.path.mkdir(parents=True)

    def _path(self, parts):
        m = hashlib.sha256()
        for p in parts:
            m.update(bytes(p, "UTF-8"))
        return self.path / m.hexdigest()

    class Object:
        def __init__(self, cache, keys):
            self.cache = cache
            self.path = self.cache._path(parts=keys)
            self.keys = keys

        def exists(self):
            return self.path.exists()

        def get_string(self):
            return self.path.read_text() if self.exists() else None

        def put_string(self, s):
            self.cache._lazy_init()
            logger.debug(f"writing cached object: {self.path}")
            self.path.write_text(s)

        def get_json(self):
            s = self.get_string()
            return s and json.loads(s)

        def put_json(self, o):
            self.put_string(json.dumps(o))

        def json(self, f):
            j = self.get_json()
            if j is None:
                j = f()
                self.put_json(j)
            return j

    class NullObject:
        def exists(self):
            return None
        def get_string(self):
            return None
        def get_json(self):
            return None

    def __call__(self, *keys):
        if self.path:
            return Cache.Object(cache=self, keys=keys)
        else:
            return Cache.NullObject()

cache = None
def setup_cache(args):
    return Cache(path=args.cache)

def lenient_datetime_parse(s):
    try:
        d = date.fromisoformat(s)
        tz = datetime.now().astimezone().tzinfo
        return datetime.combine(d, time(0, 0, 0), tz)
    except ValueError:
        pass
    try:
        return datetime.fromisoformat(s)
    except ValueError:
        t = re.sub(r"^(\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}).\d*([+-]\d{2}:\d{2})", r"\1\2", s)
        return datetime.fromisoformat(t)

class Sound:
    def __init__(self, title, artist, composer, length, url, sha1, datetime, filename, mimetype):
        self.title = title
        self.artist = artist
        self.composer = composer
        self.length = length
        self.url = url
        self.sha1 = sha1
        self.datetime = datetime
        self.filename = filename
        self.mimetype = mimetype

    def from_json(j):
        return Sound(
                title = j["title"],
                artist = j["artist"],
                composer = j["composer"],
                length = j["length"],
                url = j["url"],
                sha1 = j["sha1"],
                filename = j["filename"],
                mimetype = j.get("mimetype"),
                datetime = lenient_datetime_parse(j["date"]))

    def to_json(self):
        return {
            "title": self.title,
            "artist": self.artist,
            "composer": self.composer,
            "length": self.length,
            "url": self.url,
            "sha1": self.sha1,
            "filename": self.filename,
            "mimetype": self.mimetype,
            "date": self.datetime.isoformat()
        }

def load_sounds(args):
    b = s3.Bucket(args.bucket)

    if len(args.prefix) == 0:
        i = b.objects.all()
    else:
        i = itertools.chain(*[b.objects.filter(Prefix=p) for p in args.prefix])

    ss = set()
    for o in i:
        if not o.key.endswith(".json"):
            continue

        j = cache(b.name, o.key, o.e_tag).json(lambda: json.loads(o.get()["Body"].read()))
        s = Sound.from_json(j)
        ss.add(s)

    return ss

def list_cmd(args):
    ss = load_sounds(args)

    for s in sorted(ss, key=lambda s: s.datetime):
        print(s.url)

def compute_sha1_md5(fn):
    with open(fn, mode="rb") as f:
        sha1 = hashlib.sha1()
        md5 = hashlib.md5()
        while True:
            bs = f.read(4096)
            if len(bs) == 0: break
            sha1.update(bs)
            md5.update(bs)
        return (sha1.digest(), md5.digest())

class Profile:
    def __init__(self, filename, bucket, local, title, artist, composer, prefix):
        self.filename = filename
        self.bucket = bucket
        self.local = local
        self.title = title
        self.artist = artist
        self.composer = composer
        self.prefix = prefix

    def default():
        return Profile(
                filename = "%Y-%m-%dT%H:%M:%S%z.mp3",
                title = "Session @ %Y-%m-%dT%H:%M:%S%z",
                local = pathlib.Path.home() / "audio-journal",
                bucket = None,
                artist = None,
                composer = None,
                prefix = None)

    def from_json(j):
        return Profile(
                filename = j["filename"],
                bucket = j.get("bucket"),
                local = j.get("local"),
                title = j.get("title"),
                artist = j.get("artist"),
                composer = j.get("composer"),
                prefix = j.get("prefix"))

def postprocess(profile, wd):
    b = None
    if profile.bucket is not None:
        b = s3.Bucket(bucket)
        bl = s3_client.get_bucket_location(Bucket=b.name)["LocationConstraint"]

    [fn] = pathlib.Path(wd.name).iterdir()

    d = datetime.strptime(fn.name, profile.filename)
    af = eyed3.load(fn)
    af.tag = eyed3.id3.Tag()
    af.tag.recording_date = d.date().isoformat()
    if profile.artist is not None:
        af.tag.artist = profile.artist
    if profile.title is not None:
        af.tag.title = d.strftime(profile.title)
    if profile.composer is not None:
        af.tag.composer = profile.composer
    af.tag.save()
    duration = af.info.time_secs
    mimetype, _ = mimetypes.guess_type(fn)
    sha1, md5 = compute_sha1_md5(fn)

    if b is not None:
        if profile.prefix is not None:
            key = f"{args.prefix}/{fn.name}"
        else:
            key = fn.name

        url = "https://%s.s3.%s.amazonaws.com/%s" % (
                b.name,
                bl,
                urllib.parse.quote(key, safe="~()*!.'/"))
    else:
        url = None

    s = Sound(
            title = af.tag.title,
            artist = af.tag.artist,
            composer = af.tag.composer,
            length = duration,
            url = url,
            sha1 = sha1.hex(),
            datetime = d,
            filename = fn.name,
            mimetype = mimetype)

    metadata = bytes(json.dumps(s.to_json()), "UTF-8")

    if b is not None:
        logger.debug(f"uploading sound file: s3://{b.name}/{key}")
        with open(fn, mode="rb") as f:
            b.put_object(
                    Key = key,
                    ACL = "public-read",
                    Body = f,
                    ContentType = mimetype,
                    ContentMD5 = str(b64encode(md5), "UTF-8"))

        if args.prefix is not None:
            key = f"{args.prefix}/{fn.stem}.json"
        else:
            key = f"{fn.stem}.json"

        md5 = hashlib.md5()
        md5.update(metadata)
        md5 = md5.digest()
        logger.debug(f"uploading sound metadata: s3://{b.name}/{key}")
        b.put_object(
                Key = key,
                ACL = "public-read",
                Body = metadata,
                ContentType = "application/json",
                ContentMD5 = str(b64encode(md5), "UTF-8"))

    if profile.local is not None:
        d = pathlib.Path(profile.local)
        if profile.prefix is not None:
            d = d / pathlib.Path(profile.prefix)

        if not d.exists():
            d.mkdir(parents=True)

        target = d / fn.name
        logger.debug(f"copying local sound file: {target}")
        shutil.copy(fn, target)

        target = d / f"{fn.stem}.json"
        logger.debug(f"writing local sound metadata: {target}")
        target.write_bytes(metadata)

    if logger.level <= logging.DEBUG:
        logger.debug(f"successfully processed sound: filename={fn.name} date={d} sha1={sha1.hex()} md5={md5.hex()} length={duration} mimetype={mimetype} url={url}")
    else:
        logger.info(f"successfully processed: {s.title}")

def record_cmd(args):
    profile = Profile.default()

    class StateE(Enum):
        WAITING = 1
        RECORDING = 2
        SILENCE = 3
        STOPPING = 4

    class Server:
        def connection_made(self, transport):
            self.transport = transport

        def datagram_received(self, data, addr):
            state = StateE(data[0])
            rms = int.from_bytes(data[1:2], byteorder=sys.byteorder)
            peak = int.from_bytes(data[3:5], byteorder=sys.byteorder)
            logger.debug(f"received monitoring data: state={state} rms={rms} peak={peak}")

    async def record(wd):
        r, w = socket.socketpair(socket.AF_UNIX, socket.SOCK_DGRAM)
        w.set_inheritable(True)

        loop = asyncio.get_running_loop()
        transport, protocol = await loop.create_datagram_endpoint(lambda: Server(), sock=r)

        trec = os.environ.get("TREC", default="trec")
        p = await asyncio.create_subprocess_exec(
                trec,
                "-M", str(w.fileno()),
                "-m", str(10),
                f"{wd.name}/{profile.filename}",
                close_fds=False)
        w.close()
        ec = await p.wait()
        if ec != 0:
            raise RuntimeError(f"trac terminated with non-zero exit code: {ec}")

    async def loop():
        pps = set()
        while True:
            wd = tempfile.TemporaryDirectory(prefix="audio-journal-")
            logger.debug(f"workdir: {wd.name}")
            r = asyncio.create_task(record(wd))
            pps.add(r)
            while True:
                done, pending = await asyncio.wait(pps)
                pps -= done
                if r in done:
                    pps.add(asyncio.create_task(asyncio.to_thread(postprocess, profile, wd)))
                    break

    async def oneshot():
        wd = tempfile.TemporaryDirectory(prefix="audio-journal-")
        logger.debug(f"workdir: {wd.name}")
        await record(wd)
        postprocess(profile, wd)

    if args.loop:
        asyncio.run(loop())
    else:
        asyncio.run(oneshot())

if __name__ == "__main__":
    args = parse_args()
    logger = setup_logger(args.log.upper())
    logger.debug(f"args: {args}")

    cache = setup_cache(args)

    if args.command == "list":
        list_cmd(args)
    elif args.command == "record":
        record_cmd(args)
    else:
        raise NotImplementedError(f"subcommand {args.command}")
